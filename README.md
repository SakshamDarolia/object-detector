# pytorch-faster-rcnn
This is an object detector which uses Faster RCNN at it's backend. Faster RCNN model used here is forked from ruotianluo's pytorch-faster-rcnn repository.

## Prerequisites-
(‘.’ in the path of a file specifies the root directory of faster rcnn)

1. Make sure that you delete the cache(located under ./data/cache) files everytime the dataset is altered(whether images are added, removed or other changes), otherwise the model will throw an error because it will be reading from the old ‘.pkl’ files(in cache folder) and the original data has been changed.

2. If you are using the model for inference only then place the image files (on which inference is to be given) under ./data/demo.

3. Populate the ./data/imagenet_weights with the .pth files of the backbone CNN networks to be used for training process.

4. Place the image folders and their csv files(obtained from exporting the labels and then writing gTruth of that file, in MATLAB) in dataset folder, located in the root directory of the Faster RCNN. Remember that the names of the image folders and their csv files must be the same and start with ‘img’ prefix, followed by a number or a string.

Use the following MATLAB code to convert the .mat annotations to csv files,

	>> load(‘path/to/example.mat’)
	>> gTruth
	>> labels=objectDetectorTrainingData(gTruth)
	>> writetable(labels, ‘path/to/save/example.csv’, ‘Delimiter’, ‘ ’)

5. Make sure that name of the object classes are in line with your dataset(A general dataset may use many number of classes, like pascal voc uses 20 classes). Check for the names of classes in pascal_voc.py(located under ./lib/datasets) and demo_all_bboxes.py(located under ./tools). In demo_all_bboxes in line 195, also change the number of classes according to you data.

6. If any two or more of the image folders have a combined csv then it can be separated using ‘sep.ipynb’. Before training make sure that all datasets have their own respective csv files(not combined).

7. Make sure that you have changed the environment to ‘fasterrcnn’ from base. Use command,
	source activate fasterrcnn

Training-

1. Run the XMLconvert.ipynb.

Input – Image folders and csv files in dataset folder.
Output – a) XML files in Annotations folder.  
	     b) Images in JPEGImages folder.
	     c) ‘exp.csv’, located in root directory.
This code,
	
	a) Takes only those folders and csv files with ‘img’ prefixed in their name.
	
	b) Exports the correct csv files. In some csv files of MATLAB, there were non +ve 	annotation values(due to some different release version). These non +ve annotations were 	having value as ‘-1’ and ‘0’ only, so this code aims at converting these non +ve values to ‘1’ 	because all the annotations should be positive(as non +ve annotations dont make sense) and	first positive number after these values(-1 and 0) is 1. This correct csv file is exported to 	‘corr_csv’ located in root directory.
	
	c) Takes care of those data folders wherein one or more classes are not present in the entire 	folder. When exporting label files of such folders, the classes which are not present create a 	single empty column which interferes with the logic of the code.
	
	d) It takes only those files which are of ‘jpeg’ format, images in other formats like ‘png’ 	create problem when working with info related to images like width, height and especially 	depth(no of channels). For this purpose, ‘imghdr’ library is used to determine the format of 	images.
		
	e) Creates xml files of the images provided in the dataset folder using the data provided for 	each image in csv files. These xml files are created according to the pascal voc dataset 	format.
	
	f) Populates the Annotations and JPEGImages folders located under 	./data/VOCdevkit2007/VOC2007. ‘Annotations’ folder is populated with all the xml files 	generated and ‘JPEGImages’ folder consists of all the images provided in the dataset folder. 	The images and xml files are renumbered on the fly so that all the images from all the 	folders(in dataset folder) can be treated as a single dataset. 
	
	g) Exports a csv file named ‘exp.csv’, which will be used for creating training, validating 	and testing text files for pascal voc dataset. In this file first column of each class(recall the 	format in which MATLAB exports csv file) is present. So that we can easily check which 	objects are present in a given image. If the value under the column of a given class is -1 then 	that particular class is not present in image, otherwise(if value is a +ve integer) the class is 	present.

2. Run create.ipynb.

Input – ‘exp.csv’, generated by XMLconvert.ipynb
Output – a) trainval.txt, train.txt, val.txt and test.txt in Layout folder.
	     b) Object class specific files of the above listed files, in Main folder. Like  			     person_train.txt, person_val.txt, person_trainval.txt and person_test.txt
 
This code,
	
	a) Makes use of ‘exp.csv’ exported from XMLconvert.ipynb. So, make sure exp.csv is 	present at the root directory.
	
	b) Populates the Layout folder(located under ./data/VOCdevkit2007/VOC2007/ImageSets), 	with several files, namely train.txt, 	val.txt, trainval.txt and test.txt. These files contain the 	names(evidently numbers) of the images present in the JPEGImages(located under 	/data/VOCdevkit2007/VOC2007) folder for the different purposes as suggested by the 	name of each file.
	
	c) Populates the ‘Main’ folder(located under ./data/VOCdevkit2007/VOC2007/ImageSets), 	with four files corresponding to each class i.e. Total Files = 4*(No. Of classes). Each class 	has four files that are train, val, trainval, test. For eg, if there is a class person then the four 	files created corresponding to this class will be, person_train.txt, person_val.txt, 	person_trainval.txt and person_test.txt. These separate files will be used for train, val, 	trainval and test in case of different classes. 
		These files contain an integer(either -1 or 1) that indicates whether the 	image(specified by the number in these files) contains the object from a particular class or 	not where, ‘-1’ implies class not present and ‘1’ implies class is present in a given image.
	
	d) Copies files from Layout folder(i.e. train.txt, val.txt, trainval.txt and test.txt) into Main 	folder(needed by the code in faster rcnn).

OR

	Run create_random.ipynb to select random images for test and train. Works same as 	create.ipynb just selects images randomly.
	
3. Adjust the parameters according to yourself in ‘train_faster_rcnn.sh’, located under ./experiments/scripts. Parameters other than these are specified as command line arguments, while giving command for training in terminal.

4. Open the terminal in root directory of faster rcnn and run the following command,

	./experiments/scripts/train_faster_rcnn.sh [GPU_ID] [DATASET] [NET]

GPU_ID – If your PC has multiple GPUs then specify the number of GPU on which the model is to be trained, otherwise set it to 0(for single GPU Pcs).

DATASET – Specify the dataset that you want to use for training. Eg pascal_voc, coco etc.

NET – Specify the name of the backbone CNN model that you want to use for training. Remember to include the .pth file of desired CNN model in ./data/imagenet_weights.

A sample command would look like, 
	
	./experiments/scripts/train_faster_rcnn.sh 0 pascal_voc res101

Parameters like cfg, anchors, ratios and weights are implicitly taken care of. So, no need to worry about that.

In this Faster RCNN code, training also includes testing and evaluation at the end of the training process. So, one need not to test and evaluate separately.



Tensorboard visualisation - 

Tensorboard visualisation can be very useful to check and supervise the process of training in the form of graphs. Tensorboard consists a ton of information related to the training process in form of graphs which are very useful for interpretations related to training. For visualisation using tensorboard, 

Open a terminal window in root directory of faster rcnn and type the following command

	tensorboard --logdir=tensorboard/res101/voc_2007_trainval/ --host localhost --port=7001 &

(Please activate the environment containing tensorboard installation before the above command)


This command will give a browser link inside the terminal, copy the link and paste it in the browser to open the tensorboard window.

Tip – If the above command gives an error like, 
	‘ERROR: TensorBoard could not bind to port 7001, it was already in use’ 
then try a different port number.


After training - 

1. Trained networks(including snapshots) are saved under, 

	output/[NET]/[DATASET]_trainval/default/

2. Test outputs are saved under,

	output/[NET]/[DATASET]_test/default/

3. Tensorboard information for training and validation is saved under, 

	tensorboard/[NET]/[DATASET]/default/
	tensorboard/[NET]/[DATASET]/default_val/

Testing and evaluation - 

Although, testing and evaluation are implicitly done after the training process but if you want to perform testing explicitly, it can be done by using the following command.

	./experiments/scripts/test_faster_rcnn.sh [GPU_ID] [DATASET] [NET]

where, GPU_ID, DATASET and NET have same meanings as before,

GPU_ID – If your PC has multiple GPUs then specify the number of GPU on which the model is to be trained, otherwise set it to 0(for single GPU Pcs).

DATASET – Specify the dataset that you want to use for training. Eg pascal_voc, coco etc.

NET – Specify the name of the backbone CNN model that you want to use for training. Remember to include the .pth file of desired CNN model in ./data/imagenet_weights.

A sample command would look like, 
	./experiments/scripts/test_faster_rcnn.sh 0 pascal_voc res101


Inference(Demo) - 

Inference is the process of taking output(detection in this case) on images using a trained model. Basically, classifying data to ‘infer’ a result.

GPU_ID=0
CUDA_VISIBLE_DEVICES=${GPU_ID} ./tools/demo_all_bboxes.py

For systems having a single GPU, GPU_ID can be ignored as it will always be zero.

The demo_all_bboxes.py outputs a csv file named, ‘output_info.csv’. This file consists of columns like, target, image_name, class, bbox_x, bbox_y, bbox_w, bbox_h and conf_score. The inference is given only on the images placed in ‘demo’ folder, located under ./data. And the results inferred on all these images are stored in the output_info.csv.

Extra useful notebooks - 

create_lists.ipynb - 
Input – ‘output_info.csv’, generated by demo_all_bboxes.py
Output – List of lists containing info related to each image on which inference is done.

This notebook is used to create python lists using the ‘output_info.csv’. These lists can easily be further used in other programs for processing. At the end of this notebook a list of lists is created containing a separate list for each class in a given image in demo folder. Each list contains values specifying various parameters related to the images on which inference is done. These parameters in order are, target, image_name, class, bbox_x, bbox_y, bbox_w, bbox_h and conf_score.

data_stats_ext.ipynb -
Input – a) ‘exp.csv’, genearated by XMLconvert.ipynb
	  b) All csv files of image folders located in dataset folder
Output – data_stats_info.txt

This file tells all about the basic stats of the data used, like no. of occurences of each class and no. of occurences of small(width<32, height<32), medium(32<width<96, 32<height<96) and large(width>96, height>96) bboxes. All this information in stored in ‘data_stats_info.txt’.














Inference Results : https://drive.google.com/open?id=1Yif4OZWjfq1Z4fp3ynQVcnC3PRRjxJ31
